{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 网页爬虫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Python3中提供了urllib模块用来读取网页内容。主要包含urllib.request、urllib.response、urllib.parse和urllib.error四部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取网页内容（Python 3.x）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "import ssl\n",
    "context = ssl._create_unverified_context()  # 生成证书上下文 ( unverified 就是不验证 https 证书 )\n",
    "\n",
    "html = request.urlopen(r'http://www.baidu.com', context=context)\n",
    "\n",
    "#with open(\"pengyou.html\",\"wb\") as fp:\n",
    "#    fp.write(html.read())\n",
    "\n",
    "print(html.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<!doctype html>\\n<!--[if lt IE 7]>   <html class=\"no-js ie6 lt-ie7 lt-ie8 lt-ie9\">   <![endif]-->\\n<!--[if IE 7]>      <html class=\"no-js ie7 lt-ie8 lt-ie9\">          <![endif]-->\\n<!--[if IE 8]>      <html class=\"no-js ie8 lt-ie9\">                 <![endif]-->\\n<!--[if gt IE 8]><!--><html class=\"no-js\" lang=\"en\" dir=\"ltr\">  <!--<![endif]-->\\n\\n<head>\\n    <meta charset=\"utf-8\">\\n    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\\n\\n    <link rel=\"prefetch\" href=\"//ajax.googleapis.com/ajax/libs/jqu'\n",
      "============================================================\n",
      "ery/1.8.2/jquery.min.js\">\n",
      "    <link rel=\"prefetch\" href=\"//ajax.googleapis.com/ajax/libs/jqueryui/1.12.1/jquery-ui.min.js\">\n",
      "\n",
      "    <meta name=\"application-name\" content=\"Python.org\">\n",
      "    <meta name=\"msapplication-tooltip\" content=\"The official home of the Python Programming Language\">\n",
      "    <meta name=\"\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import ssl\n",
    "context = ssl._create_unverified_context()  # 生成证书上下文 ( unverified 就是不验证 https 证书 )\n",
    "\n",
    "fp = urllib.request.urlopen(r'http://www.python.org', context=context)\n",
    "print(fp.read(500))\n",
    "print('='*60)\n",
    "print(fp.read(300).decode())\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看是否gzip压缩方法：我们打开某个网页后，按F12进入开发者工具，点击Network>>all，查看hearders下方的Requst Headers这一项，看是否包含这样一句：\n",
    "\n",
    "Accept-Encoding: gzip, deflate, br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "import ssl\n",
    "import gzip\n",
    "context = ssl._create_unverified_context()  # 生成证书上下文 ( unverified 就是不验证 https 证书 )\n",
    "\n",
    "html = request.urlopen(r'https://ishuo.cn/', context=context)\n",
    "\n",
    "#with open(\"pengyou.html\",\"wb\") as fp:\n",
    "#    fp.write(html.read())\n",
    "\n",
    "print(gzip.decompress(html.read()).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lh/hf05nc8s2rx92_8p56r545xr0000gn/T/ipykernel_1200/1280895845.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mspilder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mspilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/lh/hf05nc8s2rx92_8p56r545xr0000gn/T/ipykernel_1200/1280895845.py\u001b[0m in \u001b[0;36mgo\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fetch_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mspilder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/lh/hf05nc8s2rx92_8p56r545xr0000gn/T/ipykernel_1200/1280895845.py\u001b[0m in \u001b[0;36m__fetch_content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fetch_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mssl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_unverified_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 生成证书上下文 ( unverified 就是不验证 https 证书 )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSpilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mhtmls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtmls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 543\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1358\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0;32m-> 1360\u001b[0;31m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0;32m-> 1317\u001b[0;31m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0m\u001b[1;32m   1318\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1242\u001b[0m                 encode_chunked=False):\n\u001b[1;32m   1243\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1244\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1288\u001b[0m             \u001b[0;31m# default charset of iso-8859-1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1290\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def request(self, method, url, body=None, headers={}, *,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\\r\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmessage_body\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotConnected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1404\u001b[0m             \u001b[0;34m\"Connect to a host on a given (SSL) port.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tunnel_host\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    936\u001b[0m         \u001b[0;34m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m         self.sock = self._create_connection(\n\u001b[0;32m--> 938\u001b[0;31m             (self.host,self.port), self.timeout, self.source_address)\n\u001b[0m\u001b[1;32m    939\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIPPROTO_TCP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTCP_NODELAY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    705\u001b[0m     \u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maddress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0msock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;31m# and socket type values to enum constants.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         addrlist.append((_intenum_converter(af, AddressFamily),\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from urllib import request\n",
    "from io import BytesIO\n",
    "import gzip\n",
    "import ssl\n",
    "\n",
    "\n",
    "class Spilder():\n",
    "\n",
    "    url='https://ishuo.cn/'\n",
    "\n",
    "    def __fetch_content(self):\n",
    "        context = ssl._create_unverified_context()  # 生成证书上下文 ( unverified 就是不验证 https 证书 )\n",
    "        r = request.urlopen(Spilder.url,context=context)\n",
    "        htmls = r.read()\n",
    "        print(htmls) \n",
    "        \n",
    "        buff = BytesIO(htmls)\n",
    "        f = gzip.GzipFile(fileobj=buff)   \n",
    "        # 以\"b’\\x1f\\x8b\\x08\"开头的 ，说明它是gzip压缩过的数据\n",
    "        # Accept-Encoding: gzip, deflate\n",
    "        htmls = f.read().decode('utf-8')\n",
    "        print(\"=\"*60)\n",
    "        print(htmls)\n",
    "\n",
    "    def go(self):\n",
    "        self.__fetch_content()\n",
    "\n",
    "spilder = Spilder()\n",
    "spilder.go()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在Python2中提供了urllib和urllib2两个模块用来读取网页内容。\n",
    "在Python3中重新进行了整合，只提供urllib一个模块，主要包含urllib.request和urllib.response、urllib.parse、urllib.error、urllib.robotparser四部分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以使用requests库来获取网页，看看requests解决上述编码问题是否更简单？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get('https://ishuo.cn/')\n",
    "\n",
    "# r = requests.get('https://api.github.com/user',auth=(\"user\",\"pass\"))\n",
    "\n",
    "print(r.status_code)\n",
    "\n",
    "print(r.headers[\"content-type\"])\n",
    "\n",
    "encode_mode = r.encoding\n",
    "print(encode_mode,'\\n',\"=\"*60)\n",
    "\n",
    "#print(r.text.encode(encode_mode).decode(\"utf-8\"))\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requests: HTTP for Humans \n",
    "\n",
    "Requests库资料地址:\n",
    "https://requests.readthedocs.io/en/master/  \n",
    "\n",
    "中文 https://requests.readthedocs.io/zh_CN/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "\n",
    "url = \"http://www.baidu.com\"\n",
    "header = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\\\n",
    "    AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.90 Safari/537.36\"\n",
    "}\n",
    "\n",
    "resp = requests.get(url, headers=header)\n",
    "pprint(resp.content.decode())\n",
    "\n",
    "# with open(\"a.txt\",\"wb\") as f:\n",
    "#     f.write(b\"hello\")\n",
    "\n",
    "with open(\"baidu.html\", \"wb\") as f:\n",
    "    f.write(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "爬取一张图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://www.baidu.com/img/bd_logo1.png?where=super\"\n",
    "header = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \\\n",
    "    AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.90 Safari/537.36\"\n",
    "}\n",
    "\n",
    "resp = requests.get(url, headers=header)\n",
    "\n",
    "with open(\"baidu.png\", \"wb\") as f:\n",
    "    f.write(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "向服务器提交数据. ASP.net中web form不支持PUT提交数据, POST提交时POST要大写\n",
    "\n",
    "https://www.cnblogs.com/wind-zhou/p/12920506.html:HTTP中GET，POST和PUT的区别\n",
    "\n",
    "HTTP请求还有一个DELETE方式，意思为删除资源， PUT为更新资源， POST为增加资源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno 60] Operation timed out>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0;32m-> 1317\u001b[0;31m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0m\u001b[1;32m   1318\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1243\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1244\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1289\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1290\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1238\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    965\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    937\u001b[0m         self.sock = self._create_connection(\n\u001b[0;32m--> 938\u001b[0;31m             (self.host,self.port), self.timeout, self.source_address)\n\u001b[0m\u001b[1;32m    939\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIPPROTO_TCP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTCP_NODELAY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    726\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    715\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# Break explicitly a reference cycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 60] Operation timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lh/hf05nc8s2rx92_8p56r545xr0000gn/T/ipykernel_1200/1166984310.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'http://www.w7vm.com/Crawler/receiver.aspx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mes_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'POST'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 543\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0mhttp_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1317\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[1;32m   1318\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1319\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1320\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno 60] Operation timed out>"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "'''header = {\n",
    "    'Accept-Charset': 'utf-8',\n",
    "    'content-type' : 'application/json'\n",
    "}\n",
    "'''\n",
    "header = {\n",
    "    'Accept-Charset': 'utf-8',\n",
    "    'content-type' : 'application/x-www-form-urlencoded',\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.61 Safari/537.36',\n",
    "}\n",
    "#DATA = b'some data'\n",
    "DATA = {'Text1':'yourname','Text2':'yourpass'}\n",
    "es_data =bytes(urllib.parse.urlencode(DATA),encoding='utf-8')\n",
    "\n",
    "#req = urllib.request.Request(url='http://www.w7vm.com/Crawler/receiver.aspx', headers=header, data=DATA,method='PUT')\n",
    "req = urllib.request.Request(url='http://www.w7vm.com/Crawler/receiver.aspx', headers=header,data=es_data,method='POST')\n",
    "\n",
    "with urllib.request.urlopen(req) as f:\n",
    "    print(f.status)\n",
    "    print(f.reason)    \n",
    "    print(f.read().decode('utf-8')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提交表单"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** http://www.musi-cal.com/cgi-bin/query 不存在\n",
    "\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import ssl\n",
    "context = ssl._create_unverified_context()\n",
    "params = urllib.parse.urlencode({'spam': 1, 'eggs': 2, 'bacon': 0})\n",
    "print(params)\n",
    "url = \"http://www.musi-cal.com/cgi-bin/query?%s\" % params    #get\n",
    "with urllib.request.urlopen(url,context=context) as f:\n",
    "        print(f.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** http://requestb.in/xrbl82xr不存在\n",
    "\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "data = urllib.parse.urlencode({'spam': 1, 'eggs': 2, 'bacon': 0})\n",
    "data = data.encode('ascii')\n",
    "with urllib.request.urlopen(\"http://requestb.in/xrbl82xr\", data) as f:   #post\n",
    "       print(f.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "使用代理服务器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "proxies = {'http': 'http://proxy.example.com:8080/'}  # 代理 http://proxy.example.com:8080\n",
    "opener = urllib.request.FancyURLopener(proxies)\n",
    "with opener.open(\"http://www.python.org\") as f:\n",
    "    f.read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 网页内容读取与域名分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分析网址"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParseResult(scheme='http', netloc='www.cwi.nl:80', path='/%7Eguido/Python.html', params='', query='', fragment='')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "o = urlparse('http://www.cwi.nl:80/%7Eguido/Python.html')\n",
    "o   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'~guido'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.parse.unquote('%7Eguido')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%E4%B8%AD%E6%96%87%E7%89%88%20%E8%B5%84%E6%96%99'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.parse.quote('中文版 资料')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'docs.python.org'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.parse import urlsplit\n",
    "url = r'https://docs.python.org/3/library/urllib.parse.html'\n",
    "r1 = urlsplit(url)\n",
    "r1.hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://docs.python.org/3/library/urllib.parse.html'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1.geturl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'docs.python.org'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1.netloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1.scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存贴吧-多页"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "import requests\n",
    "\n",
    "\n",
    "class TieBar(object):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.page = 0\n",
    "        # self.url = u\"http://tieba.baidu.com/f?kw='%s'&pn=%s\" % (name,self.page)\n",
    "        # https://tieba.baidu.com/f?kw=星空&pn=1\n",
    "        self.url = \"http://tieba.baidu.com/f?\"\n",
    "        # self.params = {\"kw\": name, \"pn\": self.page}\n",
    "        self.headers = {\n",
    "            'User-Agent': u'Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko)\\\n",
    "            Chrome / 57.0.2987.98 Safari / 537.36 LBBROWSER'}\n",
    "\n",
    "    def parse_url(self, page_num):\n",
    "        self.params = {\"kw\": self.name, \"pn\": page_num}\n",
    "        resp = requests.get(self.url, headers=self.headers, params=self.params)\n",
    "        return resp.content\n",
    "\n",
    "    def save_page(self, html, page_num):\n",
    "        file_name = u\"%s_第 %s 页.html\" % (self.name, page_num)\n",
    "        with open(file_name, \"wb\") as f:\n",
    "            f.write(html)\n",
    "\n",
    "    def save_pages(self):\n",
    "        for page_num in range(20):\n",
    "            html = self.parse_url(page_num)\n",
    "        self.save_page(html, page_num)\n",
    "\n",
    "    def run(self):\n",
    "        self.save_pages()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tie_ba = TieBar(u\"星空\")\n",
    "    tie_ba.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "提取信息 http://www.baidu.com 页面图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "url = \"http://www.baidu.com\"\n",
    "header = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \\\n",
    "    AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.90 Safari/537.36\"\n",
    "}\n",
    "\n",
    "resp = requests.get(url, headers=header)\n",
    "\n",
    "pattern = \"https://.{3,100}png\"\n",
    "html = resp.content.decode()\n",
    "res = re.findall(pattern, html)\n",
    "\n",
    "for url in res:\n",
    "    resp = requests.get(url, headers=header)\n",
    "    file_name = url.split(\"/\")[-1]\n",
    "    with open(\"images/\" + file_name, \"wb\") as f:\n",
    "        f.write(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "抓取段子网段子素材"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['如果你得罪了老板，失去的只是一份工作；如果你得罪了客户，失去的不过是一份订单；是的，世上只有一个人可以得罪：你给她脸色看，你冲她发牢骚，你大声顶撞她，甚至当 着她的面摔碗，她都不会记恨你，原因很简单，因为她是你的母亲。', '有位非常漂亮的女同事，有天起晚了没有时间化妆便急忙冲到公司。结果那天她被记旷工了……吃惊]', '悟空和唐僧一起上某卫视非诚勿扰,悟空上台,24盏灯全灭。理由:1.没房没车只有一根破棍. 2.保镖职业危险.3.动不动打妖精,对女生不温柔. 4.坐过牢,曾被压五指山下500年。唐僧上台，哗!灯全亮。 理由:1.公务员； 2.皇上兄弟，后台最硬 3.精通梵文等外语 4.长得帅 5.最关键一点：有宝马！', 'Save your heart for someone who cares. 为了某个在乎你的人，请节约你的真心！', '最新限量版 i pod ！潮爆啦！！', '有一个人叫真咯嗦，娶了个老婆叫要你管，生了个儿子叫麻烦。有一天麻烦不见了！夫妻俩就去报案。警察问爸爸：请问这位男士你叫啥名字？爸爸说:真咯嗦。警察很生气，然后 他又问妈妈叫啥名字。妈妈说:要你管。警察非常生气的说:你们要干什么?夫妻俩说：找麻烦。', '一年奔波，尘缘遇了谁；一句珍重，天涯别了谁；一点灵犀，凭栏忆了谁；一种相思，闲愁予了谁；一江明月，豪情酬了谁；一场冬雪，烟波忘了谁；一壶浊酒，相逢醉了谁；一世浮生，轻狂撩了谁；一封短信，才情念了谁；一番思量，谁是谁的谁 ；一枚围脖，转发回复谁.....', '人与人间的信任，就像是纸片，一旦破损，就不会再回到原来的样子。', '爱是一种感觉，跟时间长短没关系。——《不敢说爱你》', '师太和贫僧牵手了！！（请用四个字表达此刻感受！）', '这孩子长大了就是一祸害，你同意吗？', '有位语文老师为学生朗诵了一首陆游的《卧春》，要求学生听写出来……', '1.暧昧王:天蝎；2.犹豫不决:处女；3.朝三暮四:双子；4.逆向思维:水瓶；5.真爱无罪:双鱼；6.以史为鉴:摩羯；7.权衡利弊:金牛；8.宁缺毋滥:天秤；9.社会道德:巨蟹；10.惜时如金:白羊；11.无暇顾及:射手；12.目标明确:狮子。你是这样的吗？', '白羊：记不清人；金牛：悔未上床；双子：他（她）是青蛙（恐龙）；巨蟹：善哉善哉；狮子：一脚蹬开；处女：倒大霉了；天秤：感觉很好；天蝎：你死我活；射手：有多少次；摩羯：气死我也；水瓶：奶奶个熊；双鱼：还是想他（她）{点开大图更精彩}  @乌托邦办公室', '★做体操的猫咪你伤不起！~（@精品搞笑 ）', '哥,你是怎么用眼神杀死敌人的？？(@瞬间乐翻你 投稿)', '这歌名起的 一个比一个狠！', '今天同朋友来到一个地方,是新会、开平、台山三个地方的交界处（经国务院批准的）。因此，实现了2分钟内去新会上个厕所，过开平洗个手，再番来台山吃饭的历史创举。 （@ZCHuang）', '如果给你一次去西天取经的机会，选3个做你的徒弟，你会选谁？⒈多啦A梦。⒉柯南。⒊蜡笔小新。⒋樱木花道。⒌悟空。⒌大力水手。⒍超人。⒎功夫熊猫。⒏美少女战士。⒐路飞。⒑漩涡鸣人。⒒奥特曼。⒓卡卡西。⒔喜羊羊。⒕蜘蛛侠。⒖百变小樱。⒗忍者神龟。⒘变形金刚。⒙八神庵。⒚杀生丸。⒛阿童木', '记者：说真的，你真的会给给孩子换尿布吗？ 姚明：要不你躺下，我给你换一个！实话告诉你，我用一只脚就能给孩子换尿布，喂奶啥的，都行。 记者：我不信！ 姚明：真的，连灯都不用开。 记者：不可能！你说怎么换？ 姚明：一只脚把媳妇揣醒就得。', '失恋算个啥？轻轻的，你走吧，千万别后悔，因为只要你一挥手，就会发现，已经有那等不及的意中人，正偷偷摸摸拉你的手！', '一生只谈三次恋爱最好，一次懵懂，一次刻骨，一次一生。谈的太多会比较，无法确定；经历太多会麻木，不再相信爱情，行尸走肉，最后与不爱的人结婚，无法发自内心的爱对方，日常表现的应付，对方则抱怨你不够关心和不顾家，最后这失败的爱情，让你在遗憾和凑合中走完一生。', '1吃饭的时候咬到自己的舌头。2在车上睡着了头敲到玻璃。3玩夹子，夹到手。4坐在椅子上摇椅子，把自己摔倒了。5左脚拌右脚结果摔倒。6碰到桌子或柜子的角，巨疼。7从身上硬撕下粘贴。8拉衣服拉链夹到下巴上的肉。9踩楼梯突然踩空摔倒。都经历过，那无敌了！', '1友情:《牛仔裤的夏天》 2初恋:《情书》 3孤独:《天使爱美丽》 4坚强:《隐形的翅膀》 5成长:《千与千寻》 6自我:《穿普拉达的女王》 7尊严:《成为简奥斯汀》 8母爱:《黑暗中的舞者》 9自由:《蓝》 10智慧:《律政俏佳人》', '有一种借口叫年轻，可以不珍惜时光，不珍惜爱，不珍惜一切来之不易的东西。有一种感情叫错过，错过爱，错过可以相守的人，错过一段刻骨铭心的情。有一种寂寞叫想念，想念一个人，一段往事，一场相遇。寂静的夜里，深深切切的想念，于是深深切切地寂寞……', '我们常常看到的风景是：一个人总是仰望和羡慕着别人的幸福，一回头，却发现自己正被仰望和羡慕着。其实，每个人都是幸福的。只是，你的幸福，常常在别人眼里 。[阳光] 早安', '你病，或者不病倒，老板就在那里，不悲不喜； 你休，或者不休假，工作就在那里，不来不去； 你拼，或者不拼命，工资就在那里，不增不减； 你辞，或者不辞职，地球还是会转，不歇不停； 让我中500万，或者 让我傍个大款， 扯淡，蛋疼，淡定，悲催，关注，评论，转发！！！', '1、毕业后才知道校园恋爱是最纯洁的；2、毕业后才知道学习是最重要的；3、毕业后才知道校园生活是最幸福的；4、毕业后才知道宿舍生活是最好的；5、毕业后才知道食堂的饭菜是最便宜的；6、毕业后才知道上学是最美妙的事。7、毕业后才知道学生花钱最大手大脚......', '“我爱你”的含义是：无论贫穷，富贵，生老，病死，天灾，人祸我都不离弃的爱你。当你说出这三个字的时候，你是否有足够的勇气和顽强的毅力去承受他的人生。爱，不要轻易说出口。', '好好去爱，去生活。青春如此短暂，不要叹老。偶尔可以停下来休息，但是别蹲下来张望。走了一条路的时候，记得别回头看。时不时问问自己，自己在干嘛?记住，每天的太阳都 是新的，不要辜负了美好的晨光。', \"People cry, not because they\\\\'re weak. It\\\\'s because they\\\\'ve been strong for too long. 哭泣，不代表脆弱，只因坚强了太久。\", '他做到了，他悬空了！其实你也可以做到，站在一滩水的右上角就ok！', '一年前,学校广场上献血.200CC送一副修指甲的用具,400CC送个手表. 邻班一MM听说了感觉很幸福,跑过去问护士:&quot;1000CC送什么?&quot; 护士淡定的说:&quot;送个棺材……&quot;', '1白羊——孙悟空；2金牛——东海龙王；3双子——红孩儿；4巨蟹——观音娘娘；5狮子——玉皇大帝；6处女——唐僧；7天秤— —太白金星；8天蝎——白骨精；9射手——六耳猕猴；10魔羯——铁扇公主；11水瓶——牛魔王；12双鱼——猪八戒。', '镜子前拉一下领带；吹口哨下楼；决然地摁灭香烟；突然把车开过来，摇下车窗笑；弯腰轻抚可爱小孩的头；从背后变出一朵玫瑰；做俯卧撑，满脸是汗珠；台上讲话眼睛扫视全场；思考时额头露出川字皱纹；果决大步流星地走；正在换灯泡或钉钉子；买单时毫不迟疑拿出钱包。', '★这自行车酷吧!喜欢吗？（@趣图语录精选 ）', '妈妈语重心长的对女儿说，“从小你就不聪明，累死累活的才考上个大学，毕业后还找不到工作，现在司机要男的、编辑要男的、会计要男的、连秘书也指定要男的，妈实在为你操碎了心啊。”女儿，“555555……。”妈妈一抹脸，坚定的说，“所以趁现在老婆还能是女人，赶紧上岗，要不然过两年……”', '真de太可爱了……愿世界大同……', '有时候，面对着身边的人，突然觉得说不出话。 有时候，曾经一直坚持的东西一夜间面目全非。 有时候，想放纵自己，希望自己痛痛快快歇斯底里地发一次疯。 有时候，别人突然对你说，我觉得你变了，然后自己开始百感交集。 有时候，觉得自己拥有着整个世界，一瞬间却又觉得自己其实一无所有。', '男人就应该象自己的小弟弟， 第一 ：从不外露炫耀； 第二： 关键是时刻硬的起撑的住： 第三： 能培育出接班人； 第四： 善于攻击而又使其感到愉悦 ；第五： 既能制造摩擦又使大家同感快乐 ：第六： 胜利后能谦恭的缩小自己。 总结：低调、有骨气、有能力。。。(via@笑多了会怀孕)', '世界上最有钱的人是奥特曼，因为所有取款机上都印着他名字的缩写“ATM” 。', '语文好歹能增长你的文学知识！英语能让你与鬼佬交流！历史能让你不背叛啊！地理能让你不至于迷路啊！政治能让你知道怎样维权啊！可是数学除了毁掉整个人生还能做什么啊！泥马！！你用函数买菜啊！你去黄鹤楼还去算长江里的船距离你多远啊！你看到一排电话号码要想想它们之间有没有通项公式啊！@侯蒙恩', '女生每个月都会来月经。又把来的那个称做&quot;好朋友&quot;，但知道为何要这样称呼呢？ 把好朋友这三字拆开不就很传神了吗? &quot;女子月月有&quot;!', '只要看到他,你的坏脾气自然收敛起来,变得驯如羔羊。只要看到他,你的沮丧会消失得无影无踪。跟他一起,你才发现自己从没这么温柔过；跟他一起,你会努力表现得聪明些。——爱上了他,你有点怕他；爱上了他,你开始相信命运；是否前世你欠了他什么？谁知道,他治得了你。', '所谓爱情也不过是：看上了，追求了，好上了，开心了；不久后，腻了，吵了，淡了，散了。', '才知道，朋友就像人民币，有真、也有假，可惜我不是验钞机。', '这个指挥太有激情了，不知道是不是吃了兴奋剂~[泪]', '今天第一天上班。。有点小紧张呢~~我帅气吗？！~', '一个小男孩拿着一张假钱走进了玩具店，准备买一架玩具飞机。 服务员阿姨说：“小朋友，你的钱不是真的。 ”小男孩反问道：“阿姨，难道你的飞机是真的？”', '据说失眠的同学盯着看十分钟就能睡着了。']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "import re\n",
    "\n",
    "\n",
    "class Duanzi(object):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.url = \"https://ishuo.cn/\"\n",
    "        self.header = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \\\n",
    "            AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.90 Safari/537.36\"\n",
    "        }\n",
    "\n",
    "    def url_parse(self, url):  # 返回html数据\n",
    "        resp = requests.get(url, headers=self.header)\n",
    "        return resp.content\n",
    "\n",
    "    def save_page(self):\n",
    "        html = self.url_parse(self.url).decode()\n",
    "        # print(pn)\n",
    "        # pprint(html)\n",
    "        res = re.findall('class=\"list_li\">.+?class=\"content\">(.+?)</div><div', html,\n",
    "                         re.S)  # re.S：正则中的.不匹配\\n,加上re.S就可以匹配\n",
    "        print(res)\n",
    "        with open(\"html/%s.txt\" % (self.name), \"ab\") as f:\n",
    "            for text in res:\n",
    "                f.write(text.encode(\"utf-8\"))\n",
    "                f.write(\"\\r\\n\\r\\n\".encode(\"utf-8\"))\n",
    "\n",
    "    def run(self):\n",
    "        self.save_page()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dz = Duanzi(\"段子\")\n",
    "    dz.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作业题： 利用iciba翻译中文短语 和 段落"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "百度中译英"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "def get_page(url):\n",
    "    try:\n",
    "        response = requests.get(url,timeout=10)\n",
    "        response.raise_for_status()\n",
    "        response.encoding = response.apparent_encoding\n",
    "        return response.text\n",
    "    except:\n",
    "        print('Failed')\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse_page(html):\n",
    "    original_word = re.compile(r'class=\"Mean_word__3SsvB\">(.+?)<img',re.S)\n",
    "    translation = re.compile(r'<ul class=\"Mean_part__1RA2V\">(.+?)</ul>',re.S)\n",
    "    try:\n",
    "        original_input = re.findall(original_word,html)\n",
    "        print('\\033[1m'+original_input[0].strip()+'\\033[0m')   # 输出查询的内容\n",
    "    except:\n",
    "        print('Sorry,it is not found.')\n",
    "        print(''.center(20,'='))\n",
    "    \n",
    "    trans = re.findall(translation,html) # 匹配各词义\n",
    "\n",
    "    partofspeech = re.findall(r'<i>(.+?)</i>',trans[0],re.S)\n",
    "    print(partofspeech[0],end='\\n')\n",
    "   \n",
    "    meanings = re.findall(r'<span>(.+?)</span>',trans[0],re.S)\n",
    "    for item in meanings:\n",
    "        print(item,end='\\n')\n",
    "\n",
    "def main():\n",
    "    while True:\n",
    "        base_url = 'http://www.iciba.com/word?w='\n",
    "        word = input('Please input what you want to check(input q to exit):')\n",
    "        if word == 'q':\n",
    "            break    # 输入'q'退出查询\n",
    "        else:\n",
    "            url  = base_url + word\n",
    "            print(url)\n",
    "        html = get_page(url)\n",
    "        parse_page(html)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "段落的翻译，现在已经做了反爬虫，需要重新编写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "header = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \\\n",
    "            AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.90 Safari/537.36\"\n",
    "        }\n",
    "url = \"http://fy.iciba.com/ajax.php?\"\n",
    "str = input(\"输入你要翻译内容\")\n",
    "data = {\n",
    "    'f': 'auto',\n",
    "    't': 'auto',\n",
    "    'w': str\n",
    "}\n",
    "\n",
    "resp = requests.post(url, data=data, params={\"a\": \"fy\"}, headers = header)\n",
    "print(resp.content.decode('utf-8'))\n",
    "content = json.loads(resp.content).get(\"content\")\n",
    "content = content.get(\"out\") if content.get(\"out\") else content.get(\"word_mean\")\n",
    "pprint(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pprint  漂亮打印"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "data = (\"test\", [1, 2, 3,'test', 4, 5], \"This is a string!\",\n",
    "        {'age':23, 'gender':'F'})\n",
    "print(data)\n",
    "pprint.pprint(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "儿童故事"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "import re\n",
    "import time\n",
    "\n",
    "\n",
    "class Xgs(object):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.url = \"http://www.xigushi.com/thgs/\"\n",
    "        self.header = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.90 Safari/537.36\"}\n",
    "\n",
    "    def url_parse(self, url):  # 返回html数据\n",
    "        resp = requests.get(url, headers=self.header)\n",
    "        return resp.content\n",
    "\n",
    "    def get_link(self):\n",
    "        html = self.url_parse(self.url).decode(\"gbk\")\n",
    "        pprint(html)\n",
    "        res = re.findall('<li><a href=\"(.+?)\" target=.+?title=\"(.+?)\">.+?</a></li>',\n",
    "                         html)  # re.S：正则中的.不匹配\\n,加上re.S就可以匹配\n",
    "        # print(res)\n",
    "        infos = [(\"http://www.xigushi.com\" + info[0], info[1]) for info in res]\n",
    "        # print(infos)\n",
    "        return infos\n",
    "\n",
    "    def save_page(self):\n",
    "        infos = self.get_link()\n",
    "        with open(\"html/%s.txt\" % self.name, \"wb\") as f:\n",
    "            f.write(\"\".encode(\"utf-8\"))\n",
    "        for info in infos:\n",
    "            # info =infos[8]\n",
    "            url = info[0]\n",
    "            print(\"1*\" * 50)\n",
    "            html = self.url_parse(url).decode(\"gbk\")\n",
    "            print(\"2*\" * 50)\n",
    "            # pprint(html)\n",
    "            res = re.findall(r'<div class=\"info\">.+?</div>(.+?)<div class=\"page\">', html,\n",
    "                             re.S)  # re.S：正则中的.不匹配\\n,加上re.S就可以匹配\n",
    "            # print(res)\n",
    "\n",
    "            res = re.sub(r\"\\u3000\\u3000\", \"\", res[0])  # r表示原始字符串，\\不用多加\\\n",
    "            res = re.sub(r\"<p>|<br />|&ldquo;|&rdquo;|</br>|</p>|&nbsp;\", \"\", res)  # r表示原始字符串，\\不用多加\\\n",
    "            print(res)\n",
    "            with open(\"html/%s.txt\" % self.name, \"ab\") as f:\n",
    "                title = info[1]\n",
    "                # print(title)\n",
    "                f.write(title.encode(\"utf-8\"))\n",
    "                f.write(\"\\n\".encode(\"utf-8\"))\n",
    "            with open(\"html/%s.txt\" % self.name, \"ab\") as f:\n",
    "                f.write(res.encode(\"utf-8\"))\n",
    "                f.write(\"\\n\\n\".encode(\"utf-8\"))\n",
    "            time.sleep(2)\n",
    "\n",
    "    def run(self):\n",
    "        self.save_page()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dz = Xgs(\"儿童故事\")\n",
    "    dz.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "豆瓣电影"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "url = \"https://movie.douban.com/j/search_subjects?type=movie&tag=韩国&start=0\"\n",
    "header = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36\"}\n",
    "\n",
    "resp = requests.get(url, headers=header)\n",
    "res = json.loads(resp.content)\n",
    "print(type(res))\n",
    "# pprint(res[\"subjects\"])\n",
    "infos = res[\"subjects\"]\n",
    "for info in infos:\n",
    "    print(info[\"cover\"], info[\"title\"], info[\"url\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "豆瓣分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "\n",
    "class DouBanSpider(object):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.url = \"https://movie.douban.com/j/new_search_subjects?start={}&countries=韩国\"\n",
    "        self.header = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.90 Safari/537.36\"}\n",
    "\n",
    "        self.db_data = {\"data\": []}\n",
    "\n",
    "    def url_parse(self, url):  # 返回html数据\n",
    "\n",
    "        resp = requests.get(url, headers=self.header)\n",
    "        infos = json.loads(resp.content).get(\"data\", False)\n",
    "\n",
    "        if not infos:\n",
    "            return False\n",
    "        for info in infos:\n",
    "            dic = {\n",
    "                'directors': info['directors'],\n",
    "                'title': info['title'],\n",
    "                'detail_url': info['url'],\n",
    "                'casts': info['casts'],\n",
    "                'img': info['cover'],\n",
    "            }\n",
    "            # with open(\"josn/db.dat\", \"a\", encoding=\"utf-8\") as f:\n",
    "            #     # ensure_ascii默认True会导致中文以ascii处理，这里改为False\n",
    "            #     f.write(json.dumps(dic, ensure_ascii=False, indent=2))  # indent表示增加缩进\n",
    "            # print(\"***\",url,dic)\n",
    "            self.db_data[\"data\"].append(dic)\n",
    "\n",
    "        return True\n",
    "\n",
    "    def url_parses(self):\n",
    "        page = 0\n",
    "        print(self.url.format(page * 20))\n",
    "        while True:\n",
    "            res = self.url_parse(self.url.format(page * 20))\n",
    "            page += 1\n",
    "            print(\"page:\", page)\n",
    "            if page > 40:\n",
    "                return\n",
    "            if not res:\n",
    "                return\n",
    "\n",
    "    def save_page(self, pn=0):\n",
    "        self.url_parses()\n",
    "        with open(\"json/db.dat\", \"w\", encoding=\"utf-8\") as f:    # 文本文件\n",
    "            # ensure_ascii默认True会导致中文以ascii处理，这里改为False\n",
    "            f.write(json.dumps(self.db_data, ensure_ascii=False, indent=2))  # indent表示增加缩进\n",
    "\n",
    "    def run(self):\n",
    "        self.save_page()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    db = DouBanSpider(\"韩国分类\")\n",
    "    db.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用代理（代理已失效）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "\n",
    "url = \"http://www.baidu.com\"\n",
    "header={\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.90 Safari/537.36\"}\n",
    "proxies = {\n",
    "    \"https\": \"112.47.3.53:3128\",\n",
    "    \"https\": \"49.4.67.31:3128\",\n",
    "    \"https\": \"59.36.10.79:3128\",\n",
    "    \"https\": \"180.178.59.50:3129\"\n",
    "}\n",
    "resp = requests.get(url,headers=header,proxies=proxies)\n",
    "pprint(resp.content.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当当服饰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "import requests\n",
    "from lxml import etree\n",
    "\n",
    "class FuShiSpider(object):\n",
    "    def __init__(self):\n",
    "        self.url = \"http://category.dangdang.com/pg{}-cid4003844.html\"\n",
    "        self.headers = {\"User-Agent\": \"Mozilla/5.0 (Linux; Android 5.0; SM-G900P Build/LRX21T) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Mobile Safari/537.36\"}\n",
    "\n",
    "    def get_content(self,url):\n",
    "        html = requests.get(url, headers=self.headers)\n",
    "        html = html.content.decode(\"gbk\")\n",
    "        # print(html)\n",
    "        html = etree.HTML(html)\n",
    "\n",
    "        elements = html.xpath(\"//li[@id]/a/img\")\n",
    "\n",
    "        infos = []\n",
    "        for element in elements:\n",
    "            dict = {}\n",
    "            dict[\"img\"] = element.xpath(\"./@data-original\") if element.xpath(\"./@data-original\") else \"\"\n",
    "            if not dict[\"img\"]:\n",
    "                dict[\"img\"] = element.xpath(\"./@src\") if element.xpath(\"./@src\") else \"\"\n",
    "            # print(dict[\"img\"])\n",
    "\n",
    "            dict[\"title\"] = element.xpath(\"../@title\")[0]\n",
    "\n",
    "            dict[\"price\"] = element.xpath(\"../../p/span[@class='price_n']/text()\")[0][1:]\n",
    "\n",
    "            infos.append(dict)\n",
    "            print(dict)\n",
    "        print(infos)\n",
    "\n",
    "    def get_all_contents(self):\n",
    "        for page in range(1,2):\n",
    "            self.get_content(self.url.format(page))\n",
    "\n",
    "\n",
    "# //li[@id]/a/img/@src\n",
    "# //li[@id]/a/img/../@title\n",
    "# //li[@id]/a/img/../../p/span[@class='price_n']\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spider = FuShiSpider()\n",
    "    spider.get_all_contents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beautiful Soup 提取HTML和XML信息的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(\"<p>Some<b>bad<i>HTML\")\n",
    "print(soup.prettify())\n",
    "\n",
    "soup.find(text=\"bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 0\n",
    "for x in soup.children:\n",
    "    print(x)\n",
    "    ind += 1\n",
    "    \n",
    "print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(\"<tag1>Some<tag2/>bad<tag3>XML\", \"xml\")\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "爱丽丝梦游仙境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_doc = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   The Dormouse's story\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <p class=\"title\">\n",
      "   <b>\n",
      "    The Dormouse's story\n",
      "   </b>\n",
      "  </p>\n",
      "  <p class=\"story\">\n",
      "   Once upon a time there were three little sisters; and their names were\n",
      "   <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "    Elsie\n",
      "   </a>\n",
      "   ,\n",
      "   <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">\n",
      "    Lacie\n",
      "   </a>\n",
      "   and\n",
      "   <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">\n",
      "    Tillie\n",
      "   </a>\n",
      "   ;\n",
      "and they lived at the bottom of a well.\n",
      "  </p>\n",
      "  <p class=\"story\">\n",
      "   ...\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title.parent.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.p['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find(id=\"link3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从文档中找到所有<a>标签的链接:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://example.com/elsie\n",
      "2-http://example.com/elsie\n",
      "http://example.com/lacie\n",
      "2-http://example.com/lacie\n",
      "http://example.com/tillie\n",
      "2-http://example.com/tillie\n"
     ]
    }
   ],
   "source": [
    "for link in soup.find_all('a'):\n",
    "     print(link.get('href'))\n",
    "     print('2',link['href'],sep='-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从文档中获取所有文字内容:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以同时工作于Python2和Python3的网页爬虫程序，可以抓取指定页面中的所有链接，允许指定关键字和抓取深度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawing https://docs.python.org/3/library/index.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/../about.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/../genindex.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/../search.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/../copyright.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/intro.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/../reference/grammar.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/../bugs.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/../py-modindex.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/../index.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/functions.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/constants.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/stdtypes.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/exceptions.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/text.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/string.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/re.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/difflib.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/textwrap.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/unicodedata.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/stringprep.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/readline.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/rlcompleter.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/binary.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/struct.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/codecs.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/datatypes.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/datetime.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/zoneinfo.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/calendar.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/collections.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/collections.abc.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/heapq.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/bisect.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/array.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/weakref.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/types.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/copy.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/pprint.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/reprlib.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/enum.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/graphlib.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/numeric.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/numbers.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/math.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/cmath.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/decimal.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/fractions.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/random.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/statistics.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/functional.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/itertools.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/functools.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/operator.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/filesys.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/pathlib.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/os.path.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/fileinput.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/stat.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/filecmp.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/tempfile.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/glob.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/fnmatch.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/linecache.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/shutil.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/persistence.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/pickle.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/copyreg.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/shelve.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/marshal.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/dbm.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/sqlite3.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/archiving.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/zlib.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/gzip.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/bz2.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/lzma.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/zipfile.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/tarfile.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/fileformats.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/csv.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/configparser.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/netrc.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/xdrlib.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/plistlib.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/crypto.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/hashlib.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/hmac.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/secrets.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/allos.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/os.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/io.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/time.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/argparse.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/getopt.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/logging.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/logging.config.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/logging.handlers.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/getpass.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/curses.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/curses.ascii.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/curses.panel.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/platform.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/errno.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/ctypes.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/concurrency.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/threading.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/multiprocessing.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/multiprocessing.shared_memory.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/concurrent.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/concurrent.futures.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/subprocess.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/sched.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/queue.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/contextvars.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/_thread.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/ipc.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/asyncio.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/socket.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/ssl.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/select.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/selectors.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/asyncore.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/asynchat.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/signal.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/mmap.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/netdata.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/email.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/json.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/mailcap.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/mailbox.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/mimetypes.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/base64.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/binhex.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/binascii.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/quopri.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/uu.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/markup.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/html.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/html.parser.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/html.entities.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/xml.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/xml.etree.elementtree.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/xml.dom.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/xml.dom.minidom.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/xml.dom.pulldom.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/xml.sax.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/xml.sax.handler.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/xml.sax.utils.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/xml.sax.reader.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/pyexpat.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/internet.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/webbrowser.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/cgi.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/cgitb.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/wsgiref.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/urllib.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/urllib.request.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/urllib.parse.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/urllib.error.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/urllib.robotparser.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/http.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/http.client.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/ftplib.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/poplib.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/imaplib.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/nntplib.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/smtplib.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/smtpd.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/telnetlib.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/uuid.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/socketserver.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/http.server.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/http.cookies.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/http.cookiejar.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/xmlrpc.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/xmlrpc.client.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/xmlrpc.server.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/ipaddress.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/mm.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/audioop.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/aifc.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/sunau.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/wave.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/chunk.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/colorsys.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/imghdr.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/sndhdr.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/ossaudiodev.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/i18n.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/gettext.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/locale.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/frameworks.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/turtle.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/cmd.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/shlex.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/tk.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/tkinter.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/tkinter.colorchooser.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/tkinter.font.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/dialog.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/tkinter.messagebox.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/tkinter.scrolledtext.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/tkinter.dnd.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/tkinter.ttk.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/tkinter.tix.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/idle.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/development.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/typing.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/pydoc.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/devmode.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/doctest.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/unittest.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/unittest.mock.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/unittest.mock-examples.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/2to3.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/test.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/debug.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/audit_events.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/bdb.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/faulthandler.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/pdb.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/profile.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/timeit.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/trace.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/tracemalloc.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/distribution.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/distutils.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/ensurepip.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/venv.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/zipapp.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/python.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/sys.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/sysconfig.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/builtins.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/__main__.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/warnings.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/dataclasses.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/contextlib.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/abc.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/atexit.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/traceback.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/__future__.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/gc.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/inspect.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/site.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/custominterp.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/code.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/codeop.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/modules.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/zipimport.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/pkgutil.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/modulefinder.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/runpy.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/importlib.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/importlib.metadata.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/language.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/ast.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/symtable.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/token.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/keyword.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/tokenize.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/tabnanny.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/pyclbr.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/py_compile.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/compileall.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/dis.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/pickletools.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/windows.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/msilib.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/msvcrt.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/winreg.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/winsound.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/unix.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/posix.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/pwd.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/spwd.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/grp.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/crypt.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/termios.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/tty.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/pty.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/fcntl.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/pipes.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/resource.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/nis.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/syslog.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/superseded.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/optparse.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/imp.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/undoc.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/library/security_warnings.html...\n",
      "False None\n",
      "Crawing https://docs.python.org/3/bugs.html...\n",
      "False None\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import multiprocessing\n",
    "import re\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "try:\n",
    "    #Python 3\n",
    "    import urllib.request as lib\n",
    "    python3 = True\n",
    "except Exception:\n",
    "    #Python 2\n",
    "    import urllib as lib\n",
    "    python3 = False\n",
    "    \n",
    "def craw_links(url, depth, keywords, processed):\n",
    "    '''url:the url to craw\n",
    "       depth:the current depth to craw\n",
    "       keywords:the tuple of keywords to focus\n",
    "       pool:process pool\n",
    "    '''\n",
    "    contents = []\n",
    "    if url.startswith('http://') or url.startswith('https://'):        \n",
    "        if url not in processed:\n",
    "            #mark this url as processed\n",
    "            processed.append(url)\n",
    "        else:\n",
    "            #avoid processing the same url again\n",
    "            return\n",
    "        print('Crawing '+url+'...')\n",
    "        fp = lib.urlopen(url)\n",
    "        if python3:            \n",
    "            #Python3 returns bytes, so need to decode. \n",
    "            contents = fp.read()\n",
    "            contents_decoded = contents.decode('UTF-8')\n",
    "        else:\n",
    "            #Python2 returns str, does not need this decode\n",
    "            contents_decoded = fp.read()\n",
    "        fp.close()\n",
    "        pattern = '|'.join(keywords)\n",
    "        #if this page contains certain keywords, save it to a file\n",
    "        flag = False\n",
    "        if pattern:\n",
    "            searched = re.search(pattern, contents_decoded)\n",
    "        else:\n",
    "            #if the keywords to filter is not given, save current page\n",
    "            flag = True\n",
    "        print(flag, searched)\n",
    "        if flag or searched:\n",
    "            if python3:\n",
    "                with open('craw\\\\'+url.replace(':','_').replace('/','_'), 'wb') as fp:\n",
    "                    fp.write(contents)\n",
    "            else:\n",
    "                with open('craw\\\\'+url.replace(':','_').replace('/','_'), 'w') as fp:\n",
    "                    fp.write(contents_decoded)\n",
    "        #find all the links in the current page\n",
    "        links = re.findall('href=\"(.*?)\"', contents_decoded)\n",
    "        #craw all links in the current page\n",
    "        for link in links:\n",
    "            #consider the relative path\n",
    "            if not link.startswith(('http://','https://')):                \n",
    "                try:\n",
    "                    index = url.rindex('/')\n",
    "                    link = url[0:index+1]+link\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "            if depth>0 and link.endswith(('.htm','.html')):\n",
    "                craw_links(link, depth-1, keywords, processed)\n",
    "                \n",
    "if __name__=='__main__':   \n",
    "    processed = []   \n",
    "    keywords = ('KeyWord1','KeyWord2')\n",
    "    if not os.path.exists('craw') or not os.path.isdir('craw'):\n",
    "        os.mkdir('craw')\n",
    "    craw_links(r'https://docs.python.org/3/library/index.html', 1, keywords, processed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
