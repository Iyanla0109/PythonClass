{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获得代理ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import telnetlib\n",
    "\n",
    "def ip_test(ip,port):\n",
    "    try:\n",
    "        telnetlib.Telnet(ip,port,timeout=1.5)\n",
    "    except:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def url_parse(page):\n",
    "    url = \"https://www.kuaidaili.com/free/intr/{}/\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36\"\n",
    "    }\n",
    "    resp = requests.get(url.format(page), headers=headers)\n",
    "    ips = re.findall('\"IP\">(.+?)</td>.+?\"PORT\">(.+?)</td>', resp.content.decode(), re.S)\n",
    "    return ips\n",
    "\n",
    "def urls_parse():\n",
    "    ips = []\n",
    "    for page in range(1,10):\n",
    "        ips += url_parse(page)\n",
    "        print(ips)\n",
    "        time.sleep(1)\n",
    "    return ips\n",
    "# ret = urls_parse()\n",
    "# print(ret)\n",
    "\n",
    "def proxies_test(ips):\n",
    "    ip_ok = []\n",
    "    for ip in ips:\n",
    "        if ip_test(ip[0],ip[1]):\n",
    "            ip_ok.append(ip)\n",
    "            print(ip)\n",
    "    ip_ok = [\"%s:%s\"%(ip,port) for ip,port in ip_ok]\n",
    "\n",
    "    return ip_ok\n",
    "\n",
    "# ip_ok = proxies_test(urls_parse())\n",
    "# print(\"result:\",ip_ok)\n",
    "# ips = ['14.20.235.201:9797', '124.205.155.150:9090', '218.66.253.146:8800', '14.155.115.157:9000']\n",
    "def save_ips(ips):\n",
    "    with open(\"json/ips.json\",\"w+\") as f:\n",
    "        f.write(json.dumps(ips))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ips = urls_parse()\n",
    "    ips = proxies_test(ips)\n",
    "    ret = save_ips(ips)\n",
    "\n",
    "# print(json.dumps(ips))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用代理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import random\n",
    "\n",
    "url = \"http://httpbin.org/get\"\n",
    "url2 = \"http://icanhazip.com/\"\n",
    "url3 = \"https://www.baidu.com\"\n",
    "headers = [{\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36\"},\n",
    "    {\"User-Agent\": \"Mozilla/5.0 (Linux; Android 5.0; SM-G900P Build/LRX21T) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Mobile Safari/537.36\"}\n",
    "]\n",
    "\n",
    "def get_ips():\n",
    "    with open(\"json/ips.json\",\"r\") as f:\n",
    "        ips = f.read()\n",
    "    ips = json.loads(ips)\n",
    "    return ips\n",
    "\n",
    "def proxies_test2():\n",
    "    ips = get_ips()\n",
    "    ip = \"http://\" + random.choice(ips)\n",
    "    proxies = {\n",
    "        \"http\": ip,\n",
    "        \"https\": ip\n",
    "    }\n",
    "    resp = requests.get(url2, headers=random.choice(headers), proxies=proxies)\n",
    "    print(ip,resp.content.decode())\n",
    "\n",
    "def proxies_test3():\n",
    "    ips = get_ips()\n",
    "    for ip in  ips:\n",
    "        proxies = {\n",
    "            \"http\": ip,\n",
    "            \"https\": ip\n",
    "        }\n",
    "        try:\n",
    "            resp = requests.get(url2, headers=random.choice(headers), proxies=proxies)\n",
    "        except:\n",
    "            print(\"%s fail\"%ip)\n",
    "        else:\n",
    "            print(\"ip success %s\"%ip)\n",
    "            print(resp.content.decode())\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    ret = get_ips()\n",
    "    proxies_test3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "无头浏览器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chromedriver_mac64.zip https://chromedriver.storage.googleapis.com/index.html?path=96.0.4664.45/\n",
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.support.select import Select   # 对 select 的处理\n",
    "from selenium.webdriver.chrome.options import Options  # 无头的模块导入\n",
    "import re\n",
    "\n",
    "# 准备好参数配置   不用记  要用的时候 到时候粘过来\n",
    "opt = Options()\n",
    "opt.add_argument('--headless')\n",
    "opt.add_argument('disbale-gpu')  # 不显示\n",
    "\n",
    "web = Chrome('/usr/local/bin/chromedriver', options=opt)  # 把参数配置设置到浏览器中\n",
    "\n",
    "# ids = ['tree_' + str(i) + '_span' for i in range(1, 42)]  # 42\n",
    "# url = r'http://hn.12348.gov.cn/fxmain/subpage/legalpublicity/fx_regulations.html?objId=1394935113142247424'  # 《85普法读本》\n",
    "\n",
    "# ids = ['tree_'+str(i)+'_span' for i in range(1,8)]\n",
    "# url = 'http://hn.12348.gov.cn/fxmain/subpage/legalpublicity/fx_regulations.html?objId=1399198957574299648' #党内法规知识\n",
    "\n",
    "ids = ['tree_' + str(i) + '_span' for i in range(1, 36)]\n",
    "url = 'http://hn.12348.gov.cn/fxmain/subpage/legalpublicity/fx_regulations.html?objId=1399192447649587200'  # 2021普法读本\n",
    "\n",
    "web.get(url)\n",
    "# 怎样拿到页面代码（ 经过数据加载以及js执行之后的结果的html内容）\n",
    "# print(web.page_source) # print(web.page_source)\n",
    "\n",
    "fp = open('搜法宝.txt', 'a+')\n",
    "# 定位到导航链接 a：\n",
    "for a in ids:\n",
    "    link = web.find_element_by_xpath('//*[@id=\"{}\"]'.format(a))\n",
    "    print('-' * 60, '\\n', link.text, '\\n')\n",
    "    fp.write('-' * 60 + '\\n' + link.text + '\\n')\n",
    "    link.click()\n",
    "    time.sleep(1)\n",
    "\n",
    "    content = web.find_element_by_class_name(\"s_flzs_fnei\")\n",
    "    outHTML = content.get_attribute('innerHTML')\n",
    "    outHTML = outHTML.replace('<p', '\\n<p')\n",
    "    pattern = re.compile(r'<[^>]+>', re.S)\n",
    "    print(pattern.sub('', outHTML).replace('&nbsp;', ''))\n",
    "    fp.write(pattern.sub('', outHTML).replace('&nbsp;', ''))\n",
    "\n",
    "web.close()\n",
    "fp.close()\n",
    "print('\\n' * 4, '运行完毕！')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
